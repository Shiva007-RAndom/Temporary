The image quality of the first image is very poor which led to poor ocr. This was improved by rezising and sharpening the image.  
Tesseract was also not able to recognize the text well in other colors like red in the second image. This was resolved by converting the image to grayscale which gave better results. It struggled to recognize charaters like the dotted/dashed lines which were used in the form.
The format was retained to a moderate level.  
The text from the third image had irregular line breaks. It identified words with bigger font sizes first ignoring the placement. 
